{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d300a6a1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from torch import cuda\n",
    "device = 'cuda' if cuda.is_available() else 'cpu'\n",
    "deviceNum = 0 if cuda.is_available() else -1\n",
    "device\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae6094b8-0c61-4824-8138-813f86584846",
   "metadata": {},
   "source": [
    "# Preparing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3373c24b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "#HERE DATA IS PREPAREDs\n",
    "\n",
    "dataset = 'mba'\n",
    "data = pd.read_excel('{}/codes.xlsx'.format(dataset))\n",
    "\n",
    "print(data.iloc[:,0])\n",
    "\n",
    "def load_file(path):\n",
    "    fd = open(path).readlines()\n",
    "    fd = [x.strip() for x in fd]\n",
    "    fd = [x for x in fd if x != '']\n",
    "    fd = ' '.join(fd)\n",
    "    file_data = ' '.join(fd.split('\\n')) \n",
    "    return file_data\n",
    "\n",
    "import os\n",
    "\n",
    "def load_file_if_exists(filepath):\n",
    "    if os.path.exists(filepath):\n",
    "        return load_file(filepath)\n",
    "    else:\n",
    "        return None \n",
    "\n",
    "max_id = data['Story number'].max()\n",
    "\n",
    "# Use a dictionary comprehension with a condition that checks for file existence\n",
    "texts = {x: load_file_if_exists('{}/{}.txt'.format(dataset, str(x))) for x in data.iloc[:,0] if os.path.exists('{}/{}.txt'.format(dataset, str(x)))}\n",
    "\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad633419-362b-4057-87de-b99775dfdcc0",
   "metadata": {},
   "source": [
    "# Determining Best Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d2ba100",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [\n",
    "    'bert-base-uncased',\n",
    "    'distilbert/distilbert-base-uncased-finetuned-sst-2-english',\n",
    "    # 'FacebookAI/roberta-base',\n",
    "    # 'google/electra-base-discriminator',\n",
    "    # 'tkharisov7/aes-ielts',\n",
    "    # 'google-t5/t5-base'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5825fa44",
   "metadata": {},
   "outputs": [],
   "source": [
    "accStoresBackup = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d90e57a-ee64-40cc-873e-b6a09c98fd1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# I had to run the following linux command to get llama to use GPU\n",
    "# CUDACXX=/usr/bin/nvcc CMAKE_ARGS=\"-DLLAMA_CUBLAS=on -DCMAKE_CUDA_ARCHITECTURES=all-major\" FORCE_CMAKE=1 pip install llama-cpp-python --no-cache-dir --force-reinstall --upgrade\n",
    "#         ^^^^^^^^^^^^^  = your path to nvcc (nvidia cuda compiler)\n",
    "from llama_cpp import Llama\n",
    "\n",
    "# llama = \"./model/Meta-Llama-3-8B-Instruct.Q2_K.gguf\" # weaker but faster\n",
    "llama = \"./model/Meta-Llama-3-8B-Instruct.Q4_K_M.gguf\" #stronger but slower\n",
    "LLM = Llama(model_path=llama, n_ctx=5096)\n",
    "\n",
    "\n",
    "def llamaGuess(text, labels):\n",
    "    labelString = \", \".join(labels)\n",
    "    promptB = \"These are the sentiment labels: \" + labelString + \". Which one of the sentiment labels best describes the following text: \\\"\"\n",
    "\n",
    "    prompt = promptB + text + \"\\\" Only have the one best sentiment label in the response, nothing else. The one best sentiment label: \"\n",
    "    \n",
    "    response = LLM(prompt, max_tokens = 10, temperature=0, stop=\".\")\n",
    "    answer = response[\"choices\"][0][\"text\"]\n",
    "\n",
    "    return answer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "511b372f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# models = list of model names\n",
    "# data = list of text samples\n",
    "# labels = DataFrame of corrects answers as 1's and 0's\n",
    "# labelIndices = an index of what label corresponds to what integer\n",
    "def runModels(models, texts, data, processor=-1, debug=0):\n",
    "    # get labels\n",
    "    labels = data.keys()[1:]\n",
    "\n",
    "    #represent labels as integers\n",
    "    labelIndices = {}\n",
    "    labelIndex = 0\n",
    "    for x in labels:\n",
    "        labelIndices[x] = labelIndex\n",
    "        labelIndex+= 1\n",
    "    if(debug>=1): print(labelIndices)\n",
    "\n",
    "        \n",
    "    accScores = {}\n",
    "        \n",
    "    #we'll get an accuracy score for each model\n",
    "    for model in models:\n",
    "        pipe = pipeline(\"zero-shot-classification\", model=model, device=processor) #device>=0 for gpu supposedly\n",
    "        \n",
    "        #run current model on every sample from data       \n",
    "        golds = []\n",
    "        guesses = []\n",
    "        if(debug>=1): print(\"RUNNING\", model)\n",
    "        for i in range(len(data)):\n",
    "    \n",
    "            corrects = [] #golds for this sample\n",
    "            j = 0\n",
    "            \n",
    "            for label in labels:\n",
    "                if(data[label][i] == 1):\n",
    "                    corrects.append(j)\n",
    "                j+=1\n",
    "            if(len(corrects) == 0):\n",
    "                print(\"DATA ERROR AT INDEX\", i,\"- NO CORRECTS\")\n",
    "                continue\n",
    "    \n",
    "            #here we run the pipe and get the top choice\n",
    "            text = texts[data.iloc[:, 0][i]]\n",
    "            results = pipe(text[data.iloc[:, 0][i]],candidate_labels=labels)\n",
    "            topChoice = labelIndices[results['labels'][0]]\n",
    "    \n",
    "            #if it guessed correctly, we append the top choice to golds and guesses\n",
    "            if topChoice in corrects:\n",
    "                golds.append(topChoice)\n",
    "                guesses.append(topChoice)\n",
    "                if(debug>=2): print(\"\\tstory\", i, \"- correct: \", topChoice)\n",
    "            #if it guessed incorrectly, we append the wrong choice for each correct answer\n",
    "            else:\n",
    "                if(debug>=2): print(\"\\tstory\", i, \"- INcorrect: \", topChoice)\n",
    "                golds.append(corrects[0])\n",
    "                guesses.append(topChoice)\n",
    "        \n",
    "        finalAcc = accuracy_score(guesses,golds)\n",
    "        if(debug>=1): print(\"accuracy score for\", model, \"-\", finalAcc)\n",
    "    \n",
    "        accScores[model] = finalAcc\n",
    "        accStoresBackup[model] = finalAcc\n",
    "        \n",
    "    return accScores\n",
    "\n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67bbe2d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = runModels(models, texts, data, deviceNum, debug=2)\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ddc2979",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6ac6260-2373-47b5-a605-0cdb47a80f1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "best = max(scores)\n",
    "best"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "102e2a4a-86f5-4ea1-9c40-ad27d7e0137d",
   "metadata": {},
   "source": [
    "# Fine-Tuning Best Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a16669d-7649-4496-9a6d-ccdacd0620f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import transformers\n",
    "from transformers import AutoTokenizer,AutoModel\n",
    "\n",
    "import torch\n",
    "import tensorflow as tf\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "model_id = best\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "model = AutoModel.from_pretrained(model_id)\n",
    "\n",
    "all_devices = tf.config.list_physical_devices()\n",
    "all_devices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b843cc0-3626-48f1-8d2c-56b2554b0e20",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectors = []\n",
    "\n",
    "for t in data.iloc[:, 0]:\n",
    "    samp = []\n",
    "    tokenized = tokenizer(texts[t],return_tensors=\"pt\",truncation=True,max_length=10)\n",
    "    outputs = model(**tokenized)\n",
    "    for a in outputs[0][0]:\n",
    "        samp.extend(a)\n",
    "    vectors.append(samp)\n",
    "\n",
    "len(vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "975f5c34-faf2-482e-9c46-cfbaaaac54c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "tensors = []\n",
    "for vector in vectors:\n",
    "    # Convert each PyTorch tensor in the vector to a NumPy array\n",
    "    numpy_vector = [item.detach().cpu().numpy() if isinstance(item, torch.Tensor) else item for item in vector]\n",
    "    # Convert the list of NumPy arrays to a TensorFlow tensor\n",
    "    tensor = tf.convert_to_tensor(numpy_vector)\n",
    "    tensors.append(tensor)\n",
    "\n",
    "tensors = np.array(tensors)\n",
    "print(tensors.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a7bab64-e3a2-4f0e-bbbf-4f3f55e8a041",
   "metadata": {},
   "outputs": [],
   "source": [
    "# testPercentage = percentage of data to be used in TRAINING\n",
    "testPercentage = 70\n",
    "# split = exact number of samples to be used in training\n",
    "split = round(len(tensors) * (testPercentage / 100))\n",
    "\n",
    "y_train = data.iloc[:split, 1:].values\n",
    "print(y_train.shape)\n",
    "\n",
    "y_test = data.iloc[split:, 1:].values\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca892008-0ae1-4ba1-9faf-38ed3c66323f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras import Sequential\n",
    "\n",
    "nn = Sequential()\n",
    "nn.add(Dense(400, input_shape=(7680,),activation='relu'))\n",
    "nn.add(Dropout(0.2))\n",
    "nn.add(Dense(11, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55a08196-c347-419b-9c26-2de60e34cf57",
   "metadata": {},
   "outputs": [],
   "source": [
    "nn.compile(\n",
    "    optimizer='adam',\n",
    "    loss='binary_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8910b1f-60f8-40e2-948d-d17430fb35a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "nn.fit(tensors[:split], y_train, validation_data=(tensors[split:], y_test), epochs=20, batch_size=10, verbose=1, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af990268-99c0-4b72-831f-d5ab64c700a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss, accuracy = nn.evaluate(tensors[split:], y_test)\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "269b68dc-d80c-4a06-b174-149a84d5641a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
